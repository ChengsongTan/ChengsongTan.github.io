<font size="+2">
<h1>Comments for CXL.cache transaction layer specification--clarifications needed (2) </h1>

<!-- This is a comment and will not be rendered in the output. -->
The version we are using:
<url>  </url>
 <a href="https://www.computeexpresslink.org/_files/ugd/0c1418_1798ce97c1e6438fba818d760905e43a.pdf">CXL 3.0 spec</a>


 <p>Relevant sections in spec:<br />
	<!-- </h2>
	
	<h2 id="redundant sections">Suggestion 1 </h2>
	<h2>Our understanding of the rules and why certain parts are redundant</h2>
	-->
	<ul>
		<li><a>3.2.5.2 Device/Host Snoop-GO-Data Assumptions<br /> </a></li>
		<li><a>	3.2.5.5 Multiple Snoops to the Same Address<br />
			</a></li>
	  </ul>
	
   



</p>
	
<h2>Table of Contents</h2>
<ul>
  <li><a href="#Suggestion1">Suggestion 1</a></li>
</ul>




<h1 id="Suggestion1"> Suggestion 1 </h1>
<!-- This is a comment and will not be rendered in the output. -->

Section 3.2.5.5 mandates that only one snoop is allowed
for a device (for the same address). What it does not
disallow is having two snoops (same address) to two different devices.
 <blockquote cite= 
"https://www.computeexpresslink.org/download-the-specification
"> 
<h3>  <font color = navy> 3.2.5.5 Multiple Snoops to the Same Address </font> </h3>
The host is only allowed to have one snoop pending at a time per cacheline address per device. 
The host must wait until it has received both the snoop response and all IWB data (if any) before dispatching the next snoop to that address.
</blockquote>
This seems to imply that having two simultaneous same-block snoops
is permitted by CXL.
This could lead to either deadlocks
or incoherence, depending on which interpretation
one chooses for rule rule 3.2.5.2.
<blockquote cite= 
"https://www.computeexpresslink.org/download-the-specification
"> 
<h3> <font color = navy> 3.2.5.2 Device/Host Snoop-GO-Data Assumptions </font> </h3>
...
When the host is sending a snoop to the device, the requirement is that no GO response will be sent to any requests with that address in the device until after the Host has received a response for the snoop and all implicit writeback (IWB) data (dirty data forwarded in response to a snoop) has been received. ...

</blockquote>
Rule 3.2.5.2 says that no GOs should be sent before snoop's results
has been received.
If the action of receiving a snoop response
means processing the response and sending
the corresponding H2D Response to the requestor (GO),
then neither snoop response 1 or 2 can be processed
as that would lead to a GO being sent before a previous snoop
being received, which is a deadlock.
<div class="centered-container">
<img src="images/twoSnoopsDeadlock.png" alt="Two snoops leading to deadlock"
					width="900" height="600">
</div>
Now if we allow the action of receiving a snoop response and
sending its corresponding GO message to be non-atomic,
then a message can be buffered somewhere in the host and considered
''received''.
Then the following sequence is possible:
<div class="centered-container">
<img src="images/twoSnoopsViolation.png" alt="Two snoops leading to deadlock"
					width="900" height="600">
</div>
then
one snoop response (for example RspIHitI (2) in picture) will
be considered received first, allowing another response to 
be consumed and generate
a GO first (GO-M (1) in picture). This in turn allows
the snoop response being held at Host to be processed,
generating a second go (GO-S (2)). This clearly leads to a coherence
violation.
Either way, there is some inconsistency in the 
specification that needs to be changed.
<h2>Proposed Change </h2>
<p>Strengthen the rule 3.2.5.5 to also forbid multiple snoops to 
multiple devices:</p>

 <blockquote cite= 
"https://www.computeexpresslink.org/download-the-specification
"> 
<h3>  <font color = navy> 3.2.5.5 Multiple Snoops to the Same Address </font> </h3>
The host is only allowed to have one snoop pending at a time per cacheline address <s>per device</s>. 
The host must wait until it has received both the snoop response and all IWB data (if any) before dispatching the next snoop to that address.
</blockquote>

